readdatadf=spark.read.format('delimitedfile').option('delimiter',,).option('header','true').load('/app/test/data/source/ar_properties.csv')
readdatadf.createOrReplaceTempView('dataview')
spark.sql("SELECT src.ad_type as ad_type, src.id as id, src.end_date as end_date, src.created_on as created_on, src.lat as lat, src.l2 as l2, src.lon as lon, src.l1 as l1, src.l5 as l5, src.l3 as l3, src.l4 as l4, src.l6 as l6, src.bedrooms as bedrooms, src.rooms as rooms, src.surface_total as surface_total, src.bathrooms as bathrooms, src.surface_covered as surface_covered, src.price_period as price_period, src.price as price, src.currency as currency, src.property_type as property_type, src.title as title, src.description as description, src.operation_type as operation_type FROM dataview src  ")
