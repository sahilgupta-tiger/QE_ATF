readdatadf=spark.read.format('delimitedfile').option('delimiter',,).option('header','true').load('/app/test/data/source/ar_properties.csv')
readdatadf.createOrReplaceTempView('dataview')
spark.sql("SELECT src.ad_type as ad_type, src.start_date as start_date, src.id as id, src.end_date as end_date, src.lat as lat, src.created_on as created_on, src.lon as lon, src.l2 as l2, src.l1 as l1, src.l4 as l4, src.l3 as l3, src.l5 as l5, src.l6 as l6, src.bedrooms as bedrooms, src.rooms as rooms, src.bathrooms as bathrooms, src.surface_total as surface_total, src.surface_covered as surface_covered, src.price as price, src.currency as currency, src.price_period as price_period, src.operation_type as operation_type, src.title as title, src.description as description, src.property_type as property_type FROM dataview src  ")
