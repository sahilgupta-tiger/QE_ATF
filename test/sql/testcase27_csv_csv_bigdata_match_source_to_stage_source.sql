readdatadf=spark.read.format('delimitedfile').option('delimiter',,).option('header','true').load('/app/test/data/source/ar_properties.csv')
readdatadf.createOrReplaceTempView('dataview')
spark.sql("SELECT src.id as id, src.end_date as end_date, src.ad_type as ad_type, src.lon as lon, src.created_on as created_on, src.lat as lat, src.l1 as l1, src.l2 as l2, src.l5 as l5, src.l4 as l4, src.l3 as l3, src.rooms as rooms, src.bathrooms as bathrooms, src.l6 as l6, src.bedrooms as bedrooms, src.currency as currency, src.price as price, src.surface_covered as surface_covered, src.surface_total as surface_total, src.operation_type as operation_type, src.price_period as price_period, src.title as title, src.description as description, src.property_type as property_type FROM dataview src  ")
