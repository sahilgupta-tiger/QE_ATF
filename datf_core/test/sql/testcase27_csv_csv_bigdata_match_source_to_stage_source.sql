readdatadf=spark.read.format('delimitedfile').option('delimiter',,).option('header','true').load('file:/Workspace/Repos/sahil.gupta@tigeranalytics.com/QE_ATF/datf_core/test/data/target/ar_properties_1.csv')
readdatadf.createOrReplaceTempView('dataview')
spark.sql("SELECT src.id as id, src.ad_type as ad_type, src.end_date as end_date, src.created_on as created_on, src.lat as lat, src.lon as lon, src.l1 as l1, src.l2 as l2, src.l3 as l3, src.l4 as l4, src.l5 as l5, src.l6 as l6, src.rooms as rooms, src.bedrooms as bedrooms, src.bathrooms as bathrooms, src.surface_total as surface_total, src.surface_covered as surface_covered, src.price as price, src.currency as currency, src.price_period as price_period, src.title as title, src.property_type as property_type FROM dataview src  ")
