readdatadf=spark.read.format('delimitedfile').option('delimiter',,).option('header','true').load('/app/test/data/source/ar_properties_50.csv')
readdatadf.createOrReplaceTempView('dataview')
spark.sql("SELECT src.ad_type as ad_type, src.adtype1 as adtype1, src.adtype2 as adtype2, src.adtype3 as adtype3, src.adtype4 as adtype4, src.adtype5 as adtype5, src.bathrooms as bathrooms, src.baths as baths, src.bedrooms as bedrooms, src.built_up as built_up, src.carpet_area as carpet_area, src.children as children, src.created_on as created_on, src.currency as currency, src.denomination as denomination, src.dining as dining, src.discount_price as discount_price, src.end_date as end_date, src.id as id, src.l1 as l1, src.l2 as l2, src.l3 as l3, src.l4 as l4, src.l5 as l5, src.l6 as l6, src.lat as lat, src.living as living, src.lockin_period as lockin_period, src.lon as lon, src.master as master, src.price as price, src.price_period as price_period, src.property_type as property_type, src.proptype1 as proptype1, src.proptype2 as proptype2, src.proptype3 as proptype3, src.proptype4 as proptype4, src.proptype5 as proptype5, src.rate_card as rate_card, src.retail_price as retail_price, src.rooms as rooms, src.super_built as super_built, src.surface_covered as surface_covered, src.surface_total as surface_total, src.title as title, src.walltowall as walltowall, src.washrooms as washrooms FROM dataview src  ")
