readdatadf=spark.read.format('delimitedfile').option('delimiter',,).option('header','true').load('/app/test/data/source/patients_source.csv')
readdatadf.createOrReplaceTempView('dataview')
spark.sql("SELECT src.DEATHDATE as DEATHDATE, src.HEALTHCARE_EXPENSES as HEALTHCARE_EXPENSES, src.SUFFIX as SUFFIX, src.PASSPORT as PASSPORT, src.CITY as CITY, src.BIRTHPLACE as BIRTHPLACE, src.MAIDEN as MAIDEN, src.MARITAL as MARITAL, src.DRIVERS as DRIVERS, src.STATE as STATE, src.COUNTY as COUNTY, src.ADDRESS as ADDRESS, src.PREFIX as PREFIX, src.ZIP as ZIP, src.LON as LON, src.SSN as SSN, src.LAST as LAST, src.BIRTHDATE as BIRTHDATE, src.RACE as RACE, src.ETHNICITY as ETHNICITY, CASE WHEN src.GENDER = 'M' THEN '1' ELSE '2' END as GENDER, src.id as id, src.HEALTHCARE_COVERAGE as HEALTHCARE_COVERAGE, src.LAT as LAT, concat(src.FIRST,SRC.FIRST) as FIRST FROM dataview src  ")
